\subsubsection{Physischen Würfel als virtuelles Objekt erfassen}
\begin{description}
	\item[Fragestellung:] Wie kann ein physischer Würfel mittels den Frameworks Vision oder CoreML als virtuelles Objekt erfassen werden?
	\item[Resultat:] Vision bietet die Erkennung zweidimensonaler Elemente. Es verwendet dabei praktiken wie beim bekannten Bilderkennungsframework OpenCV, wobei ein Referenzbild hinterlegt werden muss. CoreML kann ein beliebig trainiertes Neural Network Model verwenden. Es konnte leider keine solide Möglichkeit gefunden werden 3D Objekte zu erfassen damit Sie für eine spätere Augmentierung verwendet werden können. 
	\item[Versuchsaufbau:] Für den Versuchsaufbau wurden zwei Beispielprojekte von der Apple Developer Dokumentation verwendet. Das erste Projekt "`Recognizing Images in an AR Experience"' \cite{arkit-recognize-images} verspricht bekannte 2D Bilder zu Erkennen. Anschliessend können die erkannten Koordinaten verwendet werden um AR Inhalt zu platzieren.
	Beim zweiten Projekt handelt es sich um das Thema "`Using Vision in Real Time with ARKit"' \cite{vision-real-time-with-arkit} bei dem die Frameworks Vision und CoreML zum Einsatz kommen.

	\textbf{Beispielprojekt "`Recognizing Images in an AR Experience"'}
	Das Beispielprojekt kann von der Apple Developer Website heruntergeladen werden. Anschliessen lässt sich das Projekt in XCode öffnen und muss vor der Verwendung auf dem eigenen Gerät signiert werden. Das Verzeichnis "`Ressources"' befinden sich bereits einige Demobilder die als Testversuch verwendet werden können. Damit die Genauigkeit und Geschwindigkeit getestet werden konnte wurde ein Versuch gestartet die Demobilder am Laptop anzuzeigen und anschliessend mit dem IPhone zu Erkennen. Die Erkennungsrate war schnell und zuverlässig. Das augmentierte Fläche in der sich das Bild befindet wurde korrekt angezeigt. Es wurde festgestellt, dass beim bewegen des IPhones die Fläche die Koordinaten nicht halten kann und diese Ständig neu platzieren muss.

	Darauf Folgend wurde ein eigenes Bild für die Erkennung eines cuboro Elements hinterlegt. Der Prozess wie ein eigenes Bild beigefügt werden kann wird im README.md des Beispielprojektes detailiert Erklärt. Beim Versuch wurde wie folgt vorgegangen: 

	\begin{enumerate}
		\item Bei guter Belichtung ein frontal Bild des cuboro Elements mit dem IPhone aufnehmen. 
		\item Das Bild bearbeitet dass nur die Würfelfläche beibehalten bleibt.
		\item Das Bild der Ressourcen Gruppe im XCode hinzugefügt.
		\item Neue Version auf das Testgerät geladen und probiert das Element zu Erkennen.  
	\end{enumerate}

	\bild{0.4}{cuboro-element-frontal}{Frontal Ansicht vom einem cuboro Element}


	Die Implementation der Erkennung wird in den folgenden Zeilen konfiguriert. ARKit stellt die Erkennung der Referenzbilder zur Verfügung wobei keine weiteren Implementationsschritte notwendig sind. Es wird zuerst eine Referenz auf das Ressourcenverzeichnis erstellt. Anschliessend wird diese Referenz der \texttt{ARWorldTrackingConfiguration} mitgegeben mittels \texttt{.detectionImages}.
	\begin{code}{arkit-recognition-configuration}{Implementation der Erkennung von Referenzbilder mit ARKit}
	guard let referenceImages = ARReferenceImage.referenceImages(inGroupNamed: "AR Resources", bundle: nil) else {
		fatalError("Missing expected asset catalog resources.")
	}
	
	let configuration = ARWorldTrackingConfiguration()
	configuration.detectionImages = referenceImages
	session.run(configuration, options: [.resetTracking, .removeExistingAnchors])
	\end{code}

	Wenn ein Bild aus dem Ressourcenverzeichnis erkennt wurde wird ein \texttt{ARImageAnchor} zurückgegeben. Ein \texttt{ARImageAnchor} enthält diverse informationen z.B über die Position im Koordinatensystem. Dies wird in diesem Beispiel verwendet um das Overlay zu erzeugen. 
	\begin{code}{overlay-renderer}{Implementation der \texttt{renderer(\_:nodeFor:)} Methode zur Darstellung von Flächen}
		func renderer(_ renderer: SCNSceneRenderer, didAdd node: SCNNode, for anchor: ARAnchor) {
			guard let imageAnchor = anchor as? ARImageAnchor else { return }
			let referenceImage = imageAnchor.referenceImage
			updateQueue.async {
				let plane = SCNPlane(width: referenceImage.physicalSize.width,
									height: referenceImage.physicalSize.height)
				let planeNode = SCNNode(geometry: plane)
				planeNode.opacity = 0.25
				planeNode.eulerAngles.x =  - .pi / 2
				planeNode.runAction(self.imageHighlightAction)
				node.addChildNode(planeNode)
			}

			DispatchQueue.main.async {
				let imageName = referenceImage.name ?? 
				self.statusViewController.cancelAllScheduledMessages()
				self.statusViewController.showMessage("Detected image '\(imageName)'")
			}
		}
	\end{code}


\end{description}
